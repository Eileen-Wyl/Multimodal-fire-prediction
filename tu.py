import torch
import pandas as pd
import numpy as np
from rdkit import Chem
from torch.utils.data import Dataset, DataLoader
import json
from pathlib import Path
from tqdm import tqdm
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
import re
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision import transforms
from PIL import Image
import torchvision.models as models

# ----------------------
# å›å½’ä»»åŠ¡é…ç½®ï¼ˆæ·»åŠ å›¾åƒç›¸å…³å‚æ•°ï¼‰
# ----------------------
regression_config = {
    "data_csv": "C:\\Users\\34841\\Desktop\\H1.csv",
    "smiles_column": "smiles",
    "image_column": "image_path",
    "target_column": "log(Jet Fire)",
    "numeric_columns": [
        "T", "P", "Leak Size", "Material Quantity",
        "Number of carbon atoms", "Number of hydrogen atoms",
        "Number of oxygen atoms", "Number of nitrogen atoms",
        "Number of sulfur atoms","Number of halogen atoms","Molecular Weight",
        "NFPA fire rating", "DM", "ÎµHOMO", "ÎµLUMO", "Î¼", "Î·", "Ï‰"
    ],
    "max_seq_len": 64,
    "d_model": 768,
    "image_feature_dim": 256,
    "epochs": 500,
    "batch_size": 32,
    "freeze_transformer": False,
    "freeze_image_encoder": False,
    "lr": 1e-4,
    "transformer_lr": 1e-5,
    "image_lr": 1e-5,
    "image_size": 224,
    "device": "cuda" if torch.cuda.is_available() else "cpu",
    "output_dir": "regression_output",
    "model_path": "regression_output/best_model2.pth",
    "vocab_path": "output/222vocab.json",
    "image_encoder_path": "output/image_encoder.pth",  # ä½¿ç”¨PyTorché¢„è®­ç»ƒæƒé‡
    "test_size": 0.15,
    "val_size": 0.15,
    "patience": 20
}


# ----------------------
# SMILESåˆ†è¯å™¨
# ----------------------
def smiles_tokenizer(smiles: str) -> list:
    pattern = r"(\[[^\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\||\(|\)|\.|=|#|-|\+|\\|\/|:|~|@|\?|>|\*|\$|\%[0-9]{2}|[0-9])"
    return re.findall(pattern, smiles)


# ----------------------
# å›¾åƒé¢„å¤„ç†
# ----------------------
image_transform = transforms.Compose([
    transforms.Resize((regression_config["image_size"], regression_config["image_size"])),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])


# ----------------------
# æ•°æ®é›†ç±»ï¼ˆæ·»åŠ å›¾åƒæ”¯æŒï¼‰
# ----------------------
class RegressionDataset(Dataset):
    def __init__(self, encoded_data, numeric_features, targets, original_indices,
                 split_markers, image_paths, transform=None):
        assert len(encoded_data) == len(numeric_features) == len(targets) == len(image_paths), "æ•°æ®ç»´åº¦ä¸ä¸€è‡´"
        self.data = encoded_data
        self.numeric = numeric_features
        self.targets = targets
        self.original_indices = original_indices
        self.split_markers = split_markers
        self.image_paths = image_paths
        self.transform = transform or image_transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # åŠ è½½å›¾åƒ
        img_path = self.image_paths[idx]
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
        except Exception as e:
            print(f"æ— æ³•åŠ è½½å›¾åƒ {img_path}: {str(e)}")
            # åˆ›å»ºç©ºç™½å›¾åƒä½œä¸ºæ›¿ä»£
            image = torch.zeros(3, regression_config["image_size"], regression_config["image_size"])

        return (
            torch.tensor(self.data[idx], dtype=torch.long),
            torch.tensor(self.numeric[idx].tolist(), dtype=torch.float),
            image,  # æ–°å¢ï¼šå›¾åƒå¼ é‡
            torch.tensor(self.targets[idx], dtype=torch.float),
            self.original_indices[idx],
            self.split_markers[idx]
        )


# ----------------------
# æ•°æ®é¢„å¤„ç†ï¼ˆæ·»åŠ å›¾åƒæ”¯æŒï¼‰
# ----------------------
def preprocess_data(config):
    # åŠ è½½è¯æ±‡è¡¨
    with open(config["vocab_path"]) as f:
        vocab = json.load(f)

    # è¯»å–æ•°æ®æ–‡ä»¶
    try:
        df = pd.read_csv(config["data_csv"], encoding='gbk').reset_index(drop=True)
    except UnicodeDecodeError:
        raise ValueError("æ–‡ä»¶ç¼–ç é”™è¯¯ï¼å°è¯•ä½¿ç”¨ encoding='gbk'")

    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    missing_columns = [col for col in config["numeric_columns"] + [config["image_column"]]]
    missing_columns = [col for col in missing_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"ç¼ºå°‘åˆ—: {missing_columns}")

    # å¤„ç†æ•°å€¼ç‰¹å¾
    numeric_features = df[config["numeric_columns"]].values
    imputer = SimpleImputer(strategy='mean')
    numeric_features_imputed = imputer.fit_transform(numeric_features)
    scaler = StandardScaler()
    numeric_features_scaled = scaler.fit_transform(numeric_features_imputed)

    # æ•°æ®æœ‰æ•ˆæ€§è¿‡æ»¤
    valid_data, valid_numeric_scaled, valid_numeric_original = [], [], []
    valid_targets, valid_smiles, original_indices = [], [], []
    valid_image_paths = []  # æ–°å¢ï¼šå­˜å‚¨å›¾åƒè·¯å¾„

    for idx in range(len(df)):
        s = df.iloc[idx][config["smiles_column"]]
        mol = Chem.MolFromSmiles(s)
        numeric_row_scaled = numeric_features_scaled[idx]
        numeric_row_original = numeric_features_imputed[idx]
        image_path = df.iloc[idx][config["image_column"]]  # æ–°å¢ï¼šè·å–å›¾åƒè·¯å¾„

        if mol is not None and not np.isnan(numeric_row_scaled).any() and pd.notna(image_path):
            tokens = ["[SOS]"] + smiles_tokenizer(s) + ["[EOS]"]
            ids = [vocab.get(t, vocab["[UNK]"]) for t in tokens]
            padded = ids[:config["max_seq_len"]] + [0] * (config["max_seq_len"] - len(ids))
            valid_data.append(padded)
            valid_numeric_scaled.append(numeric_row_scaled)
            valid_numeric_original.append(numeric_row_original)
            valid_targets.append(df.iloc[idx][config["target_column"]])
            valid_smiles.append(s)
            original_indices.append(idx)
            valid_image_paths.append(image_path)  # æ–°å¢

    # æ•°æ®åˆ’åˆ†
    data = np.array(valid_data)
    numeric_scaled = np.array(valid_numeric_scaled)
    numeric_original = np.array(valid_numeric_original)
    targets = np.array(valid_targets)
    original_indices = np.array(original_indices)
    image_paths = np.array(valid_image_paths)  # æ–°å¢

    # ä¸‰çº§æ•°æ®åˆ’åˆ†ï¼ˆæ·»åŠ å›¾åƒè·¯å¾„ï¼‰
    (train_val_data, test_data,
     train_val_numeric_scaled, test_numeric_scaled,
     train_val_numeric_original, test_numeric_original,
     train_val_targets, test_targets,
     train_val_indices, test_indices,
     train_val_image_paths, test_image_paths) = train_test_split(  # æ–°å¢
        data, numeric_scaled, numeric_original, targets, original_indices, image_paths,
        test_size=config["test_size"], random_state=42
    )

    (train_data, val_data,
     train_numeric_scaled, val_numeric_scaled,
     train_numeric_original, val_numeric_original,
     train_targets, val_targets,
     train_indices, val_indices,
     train_image_paths, val_image_paths) = train_test_split(  # æ–°å¢
        train_val_data, train_val_numeric_scaled, train_val_numeric_original,
        train_val_targets, train_val_indices, train_val_image_paths,
        test_size=config["val_size"], random_state=42
    )

    # ä¸ºæ¯æ¡æ•°æ®æ·»åŠ æ•°æ®é›†æ ‡è®°
    train_markers = ["train"] * len(train_data)
    val_markers = ["val"] * len(val_data)
    test_markers = ["test"] * len(test_data)

    train_indices = np.arange(len(train_data))
    val_indices = np.arange(len(val_data))
    test_indices = np.arange(len(test_data))

    return {
        "train": (train_data, train_numeric_scaled, train_targets),
        "val": (val_data, val_numeric_scaled, val_targets),
        "test": (test_data, test_numeric_scaled, test_targets),
        "smiles": valid_smiles,
        "original_indices": original_indices,
        "original_numeric": numeric_original,
        "train_original_numeric": train_numeric_original,
        "val_original_numeric": val_numeric_original,
        "test_original_numeric": test_numeric_original,
        "train_indices": train_indices,
        "val_indices": val_indices,
        "test_indices": test_indices,
        "train_markers": train_markers,
        "val_markers": val_markers,
        "test_markers": test_markers,
        "image_paths": valid_image_paths,  # æ–°å¢
        "train_image_paths": train_image_paths,  # æ–°å¢
        "val_image_paths": val_image_paths,  # æ–°å¢
        "test_image_paths": test_image_paths  # æ–°å¢
    }


# ----------------------
# å›å½’æ¨¡å‹ï¼ˆæ·»åŠ å›¾åƒç¼–ç å™¨ï¼‰
# ----------------------
class RegressionModel(torch.nn.Module):
    def __init__(self, pretrained_model, vocab_size, num_numeric):
        super().__init__()
        self.embedding = pretrained_model.embedding
        self.position_embedding = pretrained_model.position_embedding
        self.transformer = pretrained_model.transformer

        # æ•°å€¼ç‰¹å¾å¤„ç†
        self.numeric_fc = torch.nn.Sequential(
            torch.nn.Linear(num_numeric, 512),
            torch.nn.LayerNorm(512),
            torch.nn.LeakyReLU(0.1),
            torch.nn.Dropout(0.5),
            torch.nn.Linear(512, 256),
            torch.nn.LayerNorm(256),
            torch.nn.LeakyReLU(0.1)
        )

        # å›¾åƒç¼–ç å™¨ï¼ˆä½¿ç”¨ResNet50ï¼‰
        self.image_encoder = models.resnet50(pretrained=True)
        self.image_encoder.fc = torch.nn.Sequential(
            torch.nn.Linear(2048, regression_config["image_feature_dim"]),
            torch.nn.ReLU()
        )

        # å†»ç»“å›¾åƒç¼–ç å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if regression_config["freeze_image_encoder"]:
            for param in self.image_encoder.parameters():
                param.requires_grad = False

        # å›å½’å¤´ï¼ˆè°ƒæ•´è¾“å…¥ç»´åº¦ä»¥åŒ…å«å›¾åƒç‰¹å¾ï¼‰
        combined_dim = regression_config["d_model"] + 256 + regression_config["image_feature_dim"]
        self.reg_head = torch.nn.Sequential(
            torch.nn.Linear(combined_dim, 512),
            torch.nn.LayerNorm(512),
            torch.nn.LeakyReLU(0.1),
            torch.nn.Dropout(0.5),
            torch.nn.Linear(512, 1)
        )

        # å†»ç»“Transformerï¼ˆå¦‚æœéœ€è¦ï¼‰
        if regression_config["freeze_transformer"]:
            for param in self.transformer.parameters():
                param.requires_grad = False

    def forward(self, x_smiles, x_numeric, x_image):
        # SMILESç‰¹å¾æå–
        positions = torch.arange(x_smiles.size(1), device=x_smiles.device).expand(x_smiles.size(0), -1)
        x_embed = self.embedding(x_smiles) + self.position_embedding(positions)
        trans_out = self.transformer(x_embed)
        smiles_feat = trans_out[:, 0, :]

        # æ•°å€¼ç‰¹å¾æå–
        numeric_feat = self.numeric_fc(x_numeric)

        # å›¾åƒç‰¹å¾æå–
        image_feat = self.image_encoder(x_image)

        # ç‰¹å¾èåˆ
        combined = torch.cat([smiles_feat, numeric_feat, image_feat], dim=1)

        return self.reg_head(combined).squeeze()


# ----------------------
# è®­ç»ƒæµç¨‹ï¼ˆæ·»åŠ å›¾åƒå¤„ç†ï¼‰
# ----------------------
def train_regression():
    # åˆå§‹åŒ–è¾“å‡ºç›®å½•
    Path(regression_config["output_dir"]).mkdir(exist_ok=True)

    processed_data = preprocess_data(regression_config)

    # åˆ›å»ºæ•°æ®é›†ï¼ˆæ·»åŠ å›¾åƒè·¯å¾„ï¼‰
    train_dataset = RegressionDataset(
        *processed_data["train"],
        processed_data["train_indices"],
        processed_data["train_markers"],
        processed_data["train_image_paths"],  # æ–°å¢
        transform=image_transform
    )
    val_dataset = RegressionDataset(
        *processed_data["val"],
        processed_data["val_indices"],
        processed_data["val_markers"],
        processed_data["val_image_paths"],  # æ–°å¢
        transform=image_transform
    )
    test_dataset = RegressionDataset(
        *processed_data["test"],
        processed_data["test_indices"],
        processed_data["test_markers"],
        processed_data["test_image_paths"],  # æ–°å¢
        transform=image_transform
    )

    train_loader = DataLoader(train_dataset, batch_size=regression_config["batch_size"], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=regression_config["batch_size"], shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=regression_config["batch_size"], shuffle=False)

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    from yu import TransformerModel
    with open(regression_config["vocab_path"]) as f:
        vocab_size = len(json.load(f))
    pretrained_model = TransformerModel(vocab_size)
    pretrained_model.load_state_dict(torch.load("output/222pretrained_model.pth"))

    # åˆå§‹åŒ–æ¨¡å‹
    model = RegressionModel(
        pretrained_model,
        vocab_size,
        num_numeric=len(regression_config["numeric_columns"])
    ).to(regression_config["device"])

    # ä¼˜åŒ–å™¨è®¾ç½®ï¼ˆæ·»åŠ å›¾åƒç¼–ç å™¨å‚æ•°ï¼‰
    optimizer_grouped_parameters = [
        {"params": model.transformer.parameters(), "lr": regression_config["transformer_lr"]},
        {"params": model.image_encoder.parameters(), "lr": regression_config["image_lr"]},  # æ–°å¢
        {"params": model.numeric_fc.parameters(), "lr": regression_config["lr"]},
        {"params": model.reg_head.parameters(), "lr": regression_config["lr"]}
    ]
    optimizer = torch.optim.AdamW(optimizer_grouped_parameters)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)
    criterion = torch.nn.MSELoss()

    # è®­ç»ƒç›‘æ§
    best_val_loss = float('inf')
    patience_counter = 0
    metrics_history = {'train_loss': [], 'val_loss': [], 'lr': []}

    # è®­ç»ƒå¾ªç¯ï¼ˆæ·»åŠ å›¾åƒå¤„ç†ï¼‰
    for epoch in range(regression_config["epochs"]):
        model.train()
        train_loss = 0.0

        # è®­ç»ƒé˜¶æ®µ
        for smiles, numeric_feat, images, labels, original_indices, split_type in tqdm(
                train_loader, desc=f"Epoch {epoch + 1}"):
            # å°†æ•°æ®ç§»è‡³è®¾å¤‡
            smiles = smiles.to(regression_config["device"])
            numeric_feat = numeric_feat.to(regression_config["device"])
            images = images.to(regression_config["device"])
            labels = labels.to(regression_config["device"])

            optimizer.zero_grad()
            outputs = model(smiles, numeric_feat, images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for smiles, numeric_feat, images, labels, original_idx, split_type in val_loader:
                smiles = smiles.to(regression_config["device"])
                numeric_feat = numeric_feat.to(regression_config["device"])
                images = images.to(regression_config["device"])
                labels = labels.to(regression_config["device"])

                outputs = model(smiles, numeric_feat, images)
                val_loss += criterion(outputs, labels).item()

        # è®¡ç®—å¹³å‡æŸå¤±
        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        metrics_history['train_loss'].append(train_loss)
        metrics_history['val_loss'].append(val_loss)
        metrics_history['lr'].append(optimizer.param_groups[0]['lr'])

        # å­¦ä¹ ç‡è°ƒæ•´
        scheduler.step(val_loss)

        # æ—©åœé€»è¾‘
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), regression_config["model_path"])
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆéªŒè¯æŸå¤±: {val_loss:.4f}ï¼‰")
        else:
            patience_counter += 1
            if patience_counter >= regression_config["patience"]:
                print(f"â¹ æ—©åœè§¦å‘äºç¬¬ {epoch + 1} è½®ï¼Œæœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
                break

        # æ—¥å¿—è¾“å‡º
        print(f"\nEpoch {epoch + 1}/{regression_config['epochs']}")
        print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f} | éªŒè¯æŸå¤±: {val_loss:.4f}")
        print(f"å­¦ä¹ ç‡: {optimizer.param_groups[0]['lr']:.2e}")

    # åŠ è½½æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load(regression_config["model_path"]))
    model.eval()

    # è®¡ç®—è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†çš„æŒ‡æ ‡å¹¶ä¿å­˜é¢„æµ‹ç»“æœ
    for dataset_name, loader in zip(["train", "val", "test"], [train_loader, val_loader, test_loader]):
        preds, labels, original_indices = [], [], []
        numeric_features_list = []
        image_paths_list = []  # æ–°å¢

        with torch.no_grad():
            for smiles, numeric_feat, images, labels_batch, original_idx, split_type in loader:
                smiles = smiles.to(regression_config["device"])
                numeric_feat = numeric_feat.to(regression_config["device"])
                images = images.to(regression_config["device"])

                outputs = model(smiles, numeric_feat, images)
                preds.extend(outputs.detach().cpu().numpy().flatten())
                labels.extend(labels_batch.cpu().numpy().flatten())
                original_indices.extend(original_idx.cpu().numpy().flatten())

                # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©æ­£ç¡®çš„åŸå§‹æ•°å€¼
                if dataset_name == "train":
                    numeric_features_list.extend(
                        processed_data["train_original_numeric"][i]
                        for i in original_idx.cpu().numpy().flatten()
                    )
                    image_paths_list.extend(
                        processed_data["train_image_paths"][i]
                        for i in original_idx.cpu().numpy().flatten()
                    )
                elif dataset_name == "val":
                    numeric_features_list.extend(
                        processed_data["val_original_numeric"][i]
                        for i in original_idx.cpu().numpy().flatten()
                    )
                    image_paths_list.extend(
                        processed_data["val_image_paths"][i]
                        for i in original_idx.cpu().numpy().flatten()
                    )
                else:
                    numeric_features_list.extend(
                        processed_data["test_original_numeric"][i]
                        for i in original_idx.cpu().numpy().flatten()
                    )
                    image_paths_list.extend(
                        processed_data["test_image_paths"][i]
                        for i in original_idx.cpu().numpy().flatten()
                    )

        # è®¡ç®—æŒ‡æ ‡
        mse = mean_squared_error(labels, preds)
        rmse = np.sqrt(mse)
        r2 = r2_score(labels, preds)
        print(f"\nâœ… {dataset_name}é›†é¢„æµ‹ç»“æœæŒ‡æ ‡:")
        print(f"RÂ²: {r2:.4f}|MSE: {mse:.4f} | RMSE: {rmse:.4f}")

        # ä¿å­˜ç»“æœæ—¶åŒ…å«åŸå§‹è¡Œå·å’Œå›¾åƒè·¯å¾„
        results_df = pd.DataFrame({
            'åŸå§‹è¡Œå·': original_indices,
            'SMILES': [processed_data["smiles"][i] for i in original_indices],
            'å›¾åƒè·¯å¾„': image_paths_list,  # æ–°å¢
            **{col: [x[i] for x in numeric_features_list] for i, col in
               enumerate(regression_config["numeric_columns"])},
            'å®é™…å€¼': labels,
            'é¢„æµ‹å€¼': preds,
            'æ•°æ®é›†æ¥æº': dataset_name
        })
        results_df.to_csv(Path(regression_config["output_dir"]) / f"{dataset_name}_results1.csv", index=False)

    # é¢„æµ‹æ•´ä¸ªæ•°æ®é›†
    all_preds, all_labels, all_indices, all_split_types = [], [], [], []
    all_smiles = []
    all_numeric_features = []
    all_image_paths = []  # æ–°å¢

    for dataset_name, loader in zip(["train", "val", "test"], [train_loader, val_loader, test_loader]):
        for smiles, numeric_feat, images, labels, original_idx, split_type in loader:
            smiles = smiles.to(regression_config["device"])
            numeric_feat = numeric_feat.to(regression_config["device"])
            images = images.to(regression_config["device"])

            outputs = model(smiles, numeric_feat, images)
            all_preds.extend(outputs.detach().cpu().numpy().flatten())
            all_labels.extend(labels.cpu().numpy().flatten())
            all_indices.extend(original_idx.cpu().numpy().flatten())
            all_split_types.extend([split_type] * len(labels))
            all_smiles.extend([processed_data["smiles"][i] for i in original_idx])

            # è·å–åŸå§‹æ•°å€¼ç‰¹å¾
            if dataset_name == "train":
                numeric_features = processed_data["train_original_numeric"][original_idx]
                image_paths = processed_data["train_image_paths"][original_idx]  # æ–°å¢
            elif dataset_name == "val":
                numeric_features = processed_data["val_original_numeric"][original_idx]
                image_paths = processed_data["val_image_paths"][original_idx]  # æ–°å¢
            else:
                numeric_features = processed_data["test_original_numeric"][original_idx]
                image_paths = processed_data["test_image_paths"][original_idx]  # æ–°å¢

            all_numeric_features.extend(numeric_features)
            all_image_paths.extend(image_paths)  # æ–°å¢

    # ä¿å­˜å®Œæ•´ç»“æœ
    all_results_df = pd.DataFrame({
        'åŸå§‹è¡Œå·': all_indices,
        'SMILES': all_smiles,
        'å›¾åƒè·¯å¾„': all_image_paths,  # æ–°å¢
        **{col: [x[i] for x in all_numeric_features] for i, col in enumerate(regression_config["numeric_columns"])},
        'å®é™…å€¼': all_labels,
        'é¢„æµ‹å€¼': all_preds,
        'æ•°æ®é›†æ¥æº': all_split_types
    })
    all_results_df.to_csv(Path(regression_config["output_dir"]) / "all_results1.csv", index=False)

    # è®¡ç®—æ•´ä¸ªæ•°æ®é›†çš„æŒ‡æ ‡
    mse = mean_squared_error(all_labels, all_preds)
    rmse = np.sqrt(mse)
    r2 = r2_score(all_labels, all_preds)
    print(f"\nâœ… æ•´ä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœæŒ‡æ ‡:")
    print(f"RÂ²: {r2:.4f}|MSE: {mse:.4f} | RMSE: {rmse:.4f}")


if __name__ == "__main__":
    train_regression()